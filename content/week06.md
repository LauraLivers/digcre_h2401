---
layout: inner
title: 'Week 06'
---

## Intro

This week ia all about :notes: and :speaking_head:

## Schedule

| Time    | Desc                                  |
| ------- | ------------------------------------- |
| 10 mins | Catching up / Sharing and inspiration |
| 40 mins | Running models on the hub             |
| 20 mins | Running models on Replicate           |
| 5 mins  | Break                                 |
| -- mins | Self study + discussions              |

## Content

- Catching up, sharing, inspiration, etc...
- Running models on the hub (we will continung working with [the notebooks](https://github.com/gu-ma/di-ml-notebooks/tree/main) / audio)
- Running models on Replicate. See section [generate music](https://replicate.com/collections/ai-music-generation)

## Goal

The goal this week is to:

1. Understand the possibilities of Audio models
2. Test and experiment

## Going further

- Bark
  - [Suno.ai Bark](https://github.com/suno-ai/bark)
  - [Using Bark with hf transformers lib](https://huggingface.co/docs/transformers/model_doc/bark)
- Musicgen
  - [Musicgen blog post](https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/)
  - [Meta Musicgen in Audiocraft](https://github.com/facebookresearch/audiocraft)
  - [Using Musicgen with hf transformers lib](https://huggingface.co/docs/transformers/model_doc/musicgen)
- [Riffusion](https://replicate.com/riffusion/riffusion)
- RVC-Webui
  - [Repo](https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI/blob/main/docs/en/README.en.md)
- Coqui TTS
  - [TTS Repo](https://github.com/coqui-ai/TTS)
  - [xtts streaming server](https://github.com/coqui-ai/xtts-streaming-server)
